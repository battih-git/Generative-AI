{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "acb07d1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "94ca184b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from youtube_transcript_api import YouTubeTranscriptApi, TranscriptsDisabled, NoTranscriptFound\n",
    "from langchain_classic.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings, GoogleGenerativeAI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cb81a10",
   "metadata": {},
   "source": [
    "# Step 1: Indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "d70ba3ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_id = 'FuqNluMTIR8'\n",
    "\n",
    "youtube_api = YouTubeTranscriptApi()\n",
    "transcript_list = youtube_api.fetch(video_id=video_id,languages=['en'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "52e4d6de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hey there my name is Demitri and in this video \n",
      "we're going to dive into the three simple hacks  \n",
      "that you can use to get a YouTube video transcript \n",
      "and summarize it and what I often struggle with  \n",
      "is the fact that there's a lot of really great \n",
      "information in YouTube videos but unfortunately it  \n",
      "can be kind of difficult to wrap your head around \n",
      "it when it's all verbal and visual and sometimes  \n",
      "you just want to have different components written \n",
      "out so that you can actually give advice to other  \n",
      "people or remind yourself of key specific points \n",
      "from a YouTube video that were valuable and with  \n",
      "AI nowadays you can really summarize it pretty \n",
      "easily if you have the text but getting the text  \n",
      "is kind of hard so the first way that you can \n",
      "actually get this transcript generator is with  \n",
      "a Chrome extension called YouTube summary with \n",
      "chat GPT and Claude I have it installed on my  \n",
      "account and you'll see on the right hand side \n",
      "all it is is a very simple and easy to interact  \n",
      "with Chrome extension if I click on summarize \n",
      "video here it actually opens up my chat GPT  \n",
      "account and will ask it to take the transcript and \n",
      "summarize it which is really cool but for just the  \n",
      "transcript it actually is just right here it has \n",
      "timestamps where if I click on the different parts  \n",
      "of the video you'll see that I pop over right to 3 \n",
      "minutes and 21 seconds or back over to 42 seconds  \n",
      "and there are bits of text showcasing what I said \n",
      "and I'm easily able to search through it jump  \n",
      "to the current time or copy the transcript into \n",
      "plain text and ask for this summarize this YouTube  \n",
      "video on chat GPT or whatever product I want now \n",
      "there is a premium version with the summary option  \n",
      "here that you can use but I can simply just use \n",
      "chat gbt and you'll see that the summary comes  \n",
      "out really quick which is nice so that's a very \n",
      "easy way to do it if you like it from a Chrome  \n",
      "extension standpoint but if you're looking for a \n",
      "solution that's a little bit different where you  \n",
      "can go to a website and get the transcripts you \n",
      "can actually go to tactic. and use the YouTube  \n",
      "transcript tool to get a video transcript and \n",
      "you'll notice that it breaks it down actually  \n",
      "a lot better uh the time stamps on this are much \n",
      "more robust it's kind of broken down into each  \n",
      "section and I can click through to go to any of \n",
      "these time stamps and basically every sentence and  \n",
      "phrase it breaks it down in very short intervals \n",
      "as you can see they're like more closer to 5 10  \n",
      "seconds whereas this product was more like 30 to \n",
      "40 seconds so this is a much more robust tool you  \n",
      "can copy it out or even download the transcript \n",
      "very easily and it's able to be put but in right  \n",
      "here and what's really cool about that is using \n",
      "tactics upload feature you can actually take  \n",
      "that and add it to a place where you store these \n",
      "transcripts and what's great about tactic is it  \n",
      "doesn't only transcribe YouTube videos it also \n",
      "takes your meetings transcribes them and allows  \n",
      "you to analyze them with AI you can customize \n",
      "workflows so that after your meetings a sequence  \n",
      "of AI prompts will give you the answers that you \n",
      "want to the questions you have about your meeting  \n",
      "and then then send follow-ups to team members and \n",
      "share that information with anyone you'd like if  \n",
      "you want to learn more about tactic you can get \n",
      "started by trying our free Chrome extension so  \n",
      "make sure to go to tactic to add the free Chrome \n",
      "extension to your browser today to get started  \n",
      "transcribing your meetings now last but not least \n",
      "you may not want a full AI transcript and just  \n",
      "want a quick summary what I'm going to do is go \n",
      "to note gpio and then paste the link in here and  \n",
      "then click generate summary and while this will \n",
      "provide a transcript in a nice format similar to  \n",
      "30 40 seconds as the other one it also for free \n",
      "does have a summary in a very nice formatted  \n",
      "manner uh in comparison to this product it's not \n",
      "inside of it but it does have a free summary tool  \n",
      "if you want to pay for the feature to have mind \n",
      "map or AI chat you absolutely can and this product  \n",
      "actually has an entire workspace component to it \n",
      "as well it's a really cool product just a quick  \n",
      "and easy copy and paste and similarly has a lot of \n",
      "the same components as well well as some new ones  \n",
      "so if you're interested in trying out any of these \n",
      "three products to transcribe your YouTube videos  \n",
      "and get that YouTube video transcript make sure \n",
      "to click any of the links down below to try them  \n",
      "out today with that being said thank you so much \n",
      "for watching and we'll see you in the next one\n"
     ]
    }
   ],
   "source": [
    "transcript_list[0].text\n",
    "for chunk in transcript_list:\n",
    "    print(chunk.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "f2a1c6e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Descent is decent at estimating parameters. StatQuest! Hello! I'm Josh Starmer and welcome to StatQuest. Today we're going to learn about Gradient Descent and we're going to go through the algorithm step by step. Note: this StatQuest assumes you already understand the basics of least squares and linear regression, so if you're not already down with that, check out the Quest. In statistics, machine learning, and other data science fields, we optimize a lot of stuff. When we fit a line with linear regression, we optimize the intercept and the slope. When we use logistic regression, we optimize a squiggle. And when we use t-SNE, we optimize clusters. These are just a few examples of the stuff we optimize, there are tons more. The cool thing is that Gradient Descent can optimize all these things, and much more. So, if we learn how to optimize this line using Gradient Descent, then we'll have learned the strategy that optimizes this squiggle, and these clusters, and many more of the optimization problems we have in statistics, machine learning, and data science. So let's start with a simple data set. On the x-axis we have weight. On the y-axis we have height. If we fit a line to the data and someone tells us that they weigh 1.5, we can use the line to predict that they will be 1.9 tall. So let's learn how Gradient Descent can fit a line to data by finding the optimal values for the intercept and the slope. Actually, we'll start by using Gradient Descent to find the intercept. Then, once we understand how Gradient Descent works, we'll use it to solve for the intercept and the slope. So, for now, let's just plug in the Least Squares estimate for the slope, 0.64, and we'll use Gradient Descent to find the optimal value for the intercept. The first thing we do is pick a random value for the intercept. This is just an initial guess that gives Gradient Descent something to improve upon. In this case, we'll use 0, but any number will do. And that gives us the equation for this line. In this example, we will evaluate how well this line fits the data with the sum of the squared residuals. Note: in machine learning lingo, the sum of the squared residuals is a type of Loss Function. We'll talk more about Loss Functions towards the end of the video. We'll start by calculating this residual. This data point represents a person with weight 0.5 and height 1.4. We get the predicted height, the point on the line, by plugging weight equals 0.5 into the equation for the line. And the predicted height is 0.32. The residual is the difference between the observed height and the predicted height, so we calculate the difference between 1.4 and 0.32, and that gives us 1.1 for the residual. Here's the square of the first residual. The second residual is 0.4. and the third residual is 1.3. In the end, 3.1 is the sum of the squared residuals. Now, just for fun, we can plot that value on a graph. This graph has the sum of squared residuals on the y-axis, and different values for the intercept on the x-axis. This point represents the sum of the squared residuals when the intercept equals zero. However, if the intercept equals 0.25, then we would get this point on the graph. And if the intercept equals 0.5, then we would get this point. And for increasing values for the intercept we get these points. Of the points that we calculated for the graph, this one has the lowest sum of squared residuals. But is it the best we can do? What if the best value for the intercept is somewhere between these values? A slow and painful method for finding the minimal sum of the squared residuals is to plug and chug a bunch more values for the intercept. Don't despair! Gradient Descent is way more efficient. Gradient Descent only does a few calculations far from the optimal solution, and increases the number of calculations closer to the optimal value. In other words, gradient descent identifies the optimal value by taking big steps when it is far away, and baby steps when it is close. So let's get back to using gradient ascent to find the optimal value for the intercept, starting from a random value. In this case, the random value was zero. When we calculated the sum of the squared residuals, the first residual was the difference between the observed height, which was 1.4, and the predicted height, which came from the equation for this line. So we replace predicted height with the equation for the line. Since the individual weighs 0.5 we replace weight with 0.5. So, for this individual, this is their observed height and this is their predicted height. Note: we can now plug in any value for the intercept and get a new predicted height. Now let's focus on the second data point. Just like before, the residual is the difference between the observed height, which is 1.9, and the predicted height, which comes from the equation for the line. Snd since this individual weighs 2.3, we replace weight with 2.3. Now let's focus on the last person. Again, the residual is the difference between the observed height, which is 3.2, and the predicted height, which comes from the equation for the line. And since this person weighs 2.9, we'll replace weight with 2.9. Now we can easily plug in any value for the intercept and get the sum of the squared residuals. Thus, we now have an equation for this curve, and we can take the derivative of this function and determine the slope at any value for the intercept. So let's take the derivative of the sum of the squared residuals with respect to the intercept. The derivative of the sum of the squared residuals with respect to the intercept equals the derivative of the first part, plus the derivative of the second part, plus the derivative of the third part. Let's start by taking the derivative of the first part. First, we'll move this part of the equation up here, so that we have room to work. To take the derivative of this we need to apply the chain rule. So we start by moving the square to the front and multiply that by the derivative of the stuff inside the parentheses. These parts don't contain a term for the intercept, so they go away. Then we simplify by multiplying two by negative one. And this is the derivative of the first part, so we plug it in. Now we need to take the derivative of the next two parts. I'll leave that as an exercise for the viewer. Bam! Let's move the derivative up here, so that it's not taking up half the screen. Now that we have the derivative, Gradient Descent will use it to find where the sum of squared residuals is lowest. Note: if we were using least squares to solve for the optimal value for the intercept, we would simply find where the slope of the curve equals zero. In contrast gradient descent finds the minimum value by taking steps from an initial guess until it reaches the best value. This makes Gradient Descent very useful when it is not possible to solve for where the derivative equals zero. And this is why Gradient Descent can be used in so many different situations. Bam! Remember, we started by setting the intercept to a random number. In this case that was zero. So we plug zero into the derivative and we get negative 5.7. So, when the intercept equals 0, the slope of the curve equals negative 5.7. Note: the closer we get to the optimal value for the intercept, the closer the slope of the curve gets to zero. This means that when the slope of the curve is close to zero, then we should take baby steps, because we are close to the optimal value. And when the slope is far from zero, then we should take big steps because we are far from the optimal value. However, if we take a super, huge step, then we would increase the sum of the squared residuals. So the size of the step should be related to the slope, since it tells us if we should take a baby step or a big step. But we need to make sure the big step is not too big. Gradient Descent determines the step size by multiplying the slope by a small number called the learning rate. Note: we'll talk more about learning rates later. When the intercept equals 0, the step size equals negative 5.7. With the step size, we can calculate a new intercept. The new intercept is the old intercept minus the step size. So we plug in the numbers, and the new intercept equals 0.57. Bam! In one big step, we moved much closer to the optimal value for the intercept. Going back to the original data and the original line, with the intercept equals 0, we can see how much the residuals shrink when the intercept equals 0.57. Now let's take another step closer to the optimal value for the intercept. To take another step, we go back to the derivative and plug in the new intercept, and that tells us the slope of the curve equals negative 2.3. Now let's calculate the step size. By plugging in negative 2.3 for the slope, and 0.1 for the learning rate, ultimately the step size is negative 0.23. And the new intercept equals 0.8. Now we can compare the residuals when the intercept equals 0.57 to when the intercept equals 0.8. Overall the sum of the squared residuals is getting smaller. Notice that the first step was relatively large, compared to the second step. Now let's calculate the derivative at the new intercept: and we get negative 0.9. The step size equals negative 0.09, and the new intercept equals 0.89. Now we increase the intercept from 0.8 to 0.89, then we take another step and the new intercept equals 0.92. And then we take another step, and the new intercept equals 0.94. And then we take another step, and the new intercept equals 0.95. Notice how each step gets smaller and smaller the closer we get to the bottom of the curve. After six steps, the gradient ascent estimate for the intercept is 0.95. Note: the least squares estimate for the intercept is also 0.95. so we know that gradient descent has done its job, but without comparing its solution to a gold standard, how does gradient descent know to stop taking steps? Gradient Descent stops when the step size is very close to zero. The step size will be very close to zero when the slope is very close to zero. In practice, the minimum step size equals 0.001 or smaller. So if this slope equals 0.009, then we would plug in 0.009 for the slope and 0.1 for the learning rate and get 0.0009, which is smaller than 0.001, so gradient descent would stop. That said, gradient descent also includes a limit on the number of steps it will take before giving up. In practice, the maximum number of steps equals 1000 or greater. So, even if the step size is large, if there have been more than the maximum number of steps, gradient descent will stop. Okay, let's review what we've learned so far. The first thing we did is decide to use the sum of the squared residuals as the loss function to evaluate how well a line fits the data. Then, we took the derivative of the sum of the squared residuals. In other words, we took the derivative of the loss function. Then, we picked a random value for the intercept, in this case we set the intercept to be equal to zero. Then, we calculated the derivative when the intercept equals zero, plugged that slope into the step size calculation, and then calculated the new intercept, the difference between the old intercept and the step size. Lastly, we plugged the new intercept into the derivative and repeated everything until step size was close to zero. Double bam! Now that we understand how gradient descent can calculate the intercept, let's talk about how to estimate the intercept and the slope. Just like before, we'll use the sum of the squared residuals as the loss function. This is a 3D graph of the loss function for the different values for the intercept and the slope. This axis is the sum of the squared residuals, this axis represents different values for the slope, and this axis represents different values for the intercept. We want to find the values for the intercept and slope that give us the minimum sum of the squared residuals. So, just like before, we need to take the derivative of this function. And just like before, we'll take the derivative with respect to the intercept. But, unlike before, we'll also take the derivative with respect to the slope. We'll start by taking the derivative with respect to the intercept. Just like before, we'll take the derivative of each part. And, just like before, we'll use the chain rule and move the square to the front, and multiply that by the derivative of the stuff inside the parentheses. [Music] Since we are taking the derivative with respect to the intercept, we treat the slope like a constant, and the derivative of a constant is zero. So, we end up with negative one, just like before. Then we simplify by multiplying two by negative one. And this is the derivative of the first part. So we plug it in. Likewise, we replace these terms with their derivatives. So this whole thing is the derivative of the sum of squared residuals with respect to the intercept. Now let's take the derivative of the sum of the squared residuals with respect to the slope. Just like before, we take the derivative of each part and, just like before, we'll use the chain rule to move the square to the front and multiply that by the derivative of the stuff inside the parentheses. Since we are taking the derivative with respect to the slope, we treat the intercept like a constant and the derivative of a constant is zero. So we end up with negative 0.5. Then we simplify by moving the negative 0.5 to the front. Note: I left the 0.5 in bold instead of multiplying it by 2 to remind us that 0.5 is the weight for the first sample. And this is the derivative of the first part. So we plug it in. Likewise, we replace these terms with their derivatives. Again, 2.3 and 2.9 are in bold to remind us that they are the weights of the second and third samples. Here's the derivative of the sum of the squared residuals with respect to the intercept, and here's the derivative with respect to the slope. Note: when you have two or more derivatives of the same function they are called a gradient. We will use this gradient to descend to the lowest point in the loss function, which, in this case, is the sum of the squared residuals. Thus, this is why the algorithm is called Gradient Descent. Bam! Just like before, we'll start by picking a random number for the intercept. In this case, we'll set the intercept to be equal to zero, and we'll pick a random number for the slope. In this case we'll set the slope to be 1. Thus, this line, with intercept equals 0 and slope equals 1, is where we will start. Now, let's plug in 0 for the intercept and 1 for the slope. And that gives us two slopes. Now, we plug the slopes into the step size formulas, and multiply by the learning rate, which this time we set to 0.01. Note: The larger learning rate that we used in the first example doesn't work this time. Even after a bunch of steps, Gradient Descent doesn't arrive at the correct answer. This means that Gradient Descent can be very sensitive to the learning rate. The good news is that, in practice, a reasonable learning rate can be determined automatically by starting large and getting smaller with each step. So, in theory, you shouldn't have to worry too much about the learning rate. Anyway, we do the math and get two step sizes. Now we calculate the new intercept and new slope by plugging in the old intercept and the old slope, and the step sizes. And we end up with a new intercept and a new slope. This is the line we started with and this is the new line after the first step. Now we just repeat what we did until all of the step sizes are very small, or we reach the maximum number of steps. This is the best fitting line, with intercept equals 0.95 and slope equals 0.64,  the same values we get from least squares. Double bam! We now know how Gradient Descent optimizes two parameters, the slope and the intercept. If we had more parameters then we just take more derivatives and everything else stays the same. Triple bam! Note: the sum of the squared residuals is just one type of Loss Function. However, there are tons of other loss functions that work with other types of data. Regardless of which Loss Function you use, Gradient Descent works the same way. Step 1: take the derivative of the loss function for each parameter in it. In fancy machine learning lingo, take the gradient of the loss function. Step 2: pick random values for the parameters. Step 3: plug the parameter values into the derivatives (ahem, the gradient). Step 4: calculate the step sizes. Step 5: calculate the new parameters. Now go back to step 3 and repeat until step size is very small or you reach the maximum number of steps. One last thing before we're done. In our example we only had three data points, so the math didn't take very long. But when you have millions of data points it can take a long time. So there is a thing called Stochastic Gradient Descent that uses a randomly selected subset of the data at every step rather than the full data set. This reduces the time spent calculating the derivatives of the loss function. That's all. Stochastic Gradient Descent sounds fancy, but it's no big deal. Hooray! We've made it to the end of another exciting StatQuest. If you like this StatQuest and want to see more, please subscribe. And if you want to support StatQuest, well, consider buying one or two of my original songs, or buying a StatQuest t-shirt or hoodie. The links are in the description below. Alright, until next time. Quest on!\n"
     ]
    }
   ],
   "source": [
    "video_id = 'sDv4f4s2SB8'\n",
    "try:\n",
    "    # If you don't care which language, this returns the best one\n",
    "    youtube_api = YouTubeTranscriptApi()\n",
    "    transcript_list = youtube_api.fetch(video_id, languages=['en'])\n",
    "\n",
    "    # Flatten it to plain text\n",
    "    transcript = ' '.join(chunk.text for chunk in transcript_list)\n",
    "    print(transcript)\n",
    "\n",
    "except Exception as e:\n",
    "    print('No Captions available for this video.')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34ada43e",
   "metadata": {},
   "source": [
    "# Step 2: Indexing (Text Splitting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "151cb0a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_classic.text_splitter import RecursiveCharacterTextSplitter\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size = 1000, chunk_overlap=200)\n",
    "chunks = splitter.create_documents([transcript])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "3edf9ac6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "1a7b2c93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={}, page_content=\"Gradient Descent is decent at estimating parameters. StatQuest! Hello! I'm Josh Starmer and welcome to StatQuest. Today we're going to learn about Gradient Descent and we're going to go through the algorithm step by step. Note: this StatQuest assumes you already understand the basics of least squares and linear regression, so if you're not already down with that, check out the Quest. In statistics, machine learning, and other data science fields, we optimize a lot of stuff. When we fit a line with linear regression, we optimize the intercept and the slope. When we use logistic regression, we optimize a squiggle. And when we use t-SNE, we optimize clusters. These are just a few examples of the stuff we optimize, there are tons more. The cool thing is that Gradient Descent can optimize all these things, and much more. So, if we learn how to optimize this line using Gradient Descent, then we'll have learned the strategy that optimizes this squiggle, and these clusters, and many more of\"),\n",
       " Document(metadata={}, page_content=\"these things, and much more. So, if we learn how to optimize this line using Gradient Descent, then we'll have learned the strategy that optimizes this squiggle, and these clusters, and many more of the optimization problems we have in statistics, machine learning, and data science. So let's start with a simple data set. On the x-axis we have weight. On the y-axis we have height. If we fit a line to the data and someone tells us that they weigh 1.5, we can use the line to predict that they will be 1.9 tall. So let's learn how Gradient Descent can fit a line to data by finding the optimal values for the intercept and the slope. Actually, we'll start by using Gradient Descent to find the intercept. Then, once we understand how Gradient Descent works, we'll use it to solve for the intercept and the slope. So, for now, let's just plug in the Least Squares estimate for the slope, 0.64, and we'll use Gradient Descent to find the optimal value for the intercept. The first thing we do is pick\"),\n",
       " Document(metadata={}, page_content=\"the slope. So, for now, let's just plug in the Least Squares estimate for the slope, 0.64, and we'll use Gradient Descent to find the optimal value for the intercept. The first thing we do is pick a random value for the intercept. This is just an initial guess that gives Gradient Descent something to improve upon. In this case, we'll use 0, but any number will do. And that gives us the equation for this line. In this example, we will evaluate how well this line fits the data with the sum of the squared residuals. Note: in machine learning lingo, the sum of the squared residuals is a type of Loss Function. We'll talk more about Loss Functions towards the end of the video. We'll start by calculating this residual. This data point represents a person with weight 0.5 and height 1.4. We get the predicted height, the point on the line, by plugging weight equals 0.5 into the equation for the line. And the predicted height is 0.32. The residual is the difference between the observed height\"),\n",
       " Document(metadata={}, page_content=\"the predicted height, the point on the line, by plugging weight equals 0.5 into the equation for the line. And the predicted height is 0.32. The residual is the difference between the observed height and the predicted height, so we calculate the difference between 1.4 and 0.32, and that gives us 1.1 for the residual. Here's the square of the first residual. The second residual is 0.4. and the third residual is 1.3. In the end, 3.1 is the sum of the squared residuals. Now, just for fun, we can plot that value on a graph. This graph has the sum of squared residuals on the y-axis, and different values for the intercept on the x-axis. This point represents the sum of the squared residuals when the intercept equals zero. However, if the intercept equals 0.25, then we would get this point on the graph. And if the intercept equals 0.5, then we would get this point. And for increasing values for the intercept we get these points. Of the points that we calculated for the graph, this one has\"),\n",
       " Document(metadata={}, page_content=\"the graph. And if the intercept equals 0.5, then we would get this point. And for increasing values for the intercept we get these points. Of the points that we calculated for the graph, this one has the lowest sum of squared residuals. But is it the best we can do? What if the best value for the intercept is somewhere between these values? A slow and painful method for finding the minimal sum of the squared residuals is to plug and chug a bunch more values for the intercept. Don't despair! Gradient Descent is way more efficient. Gradient Descent only does a few calculations far from the optimal solution, and increases the number of calculations closer to the optimal value. In other words, gradient descent identifies the optimal value by taking big steps when it is far away, and baby steps when it is close. So let's get back to using gradient ascent to find the optimal value for the intercept, starting from a random value. In this case, the random value was zero. When we calculated\"),\n",
       " Document(metadata={}, page_content=\"when it is close. So let's get back to using gradient ascent to find the optimal value for the intercept, starting from a random value. In this case, the random value was zero. When we calculated the sum of the squared residuals, the first residual was the difference between the observed height, which was 1.4, and the predicted height, which came from the equation for this line. So we replace predicted height with the equation for the line. Since the individual weighs 0.5 we replace weight with 0.5. So, for this individual, this is their observed height and this is their predicted height. Note: we can now plug in any value for the intercept and get a new predicted height. Now let's focus on the second data point. Just like before, the residual is the difference between the observed height, which is 1.9, and the predicted height, which comes from the equation for the line. Snd since this individual weighs 2.3, we replace weight with 2.3. Now let's focus on the last person. Again, the\"),\n",
       " Document(metadata={}, page_content=\"which is 1.9, and the predicted height, which comes from the equation for the line. Snd since this individual weighs 2.3, we replace weight with 2.3. Now let's focus on the last person. Again, the residual is the difference between the observed height, which is 3.2, and the predicted height, which comes from the equation for the line. And since this person weighs 2.9, we'll replace weight with 2.9. Now we can easily plug in any value for the intercept and get the sum of the squared residuals. Thus, we now have an equation for this curve, and we can take the derivative of this function and determine the slope at any value for the intercept. So let's take the derivative of the sum of the squared residuals with respect to the intercept. The derivative of the sum of the squared residuals with respect to the intercept equals the derivative of the first part, plus the derivative of the second part, plus the derivative of the third part. Let's start by taking the derivative of the first\"),\n",
       " Document(metadata={}, page_content=\"with respect to the intercept equals the derivative of the first part, plus the derivative of the second part, plus the derivative of the third part. Let's start by taking the derivative of the first part. First, we'll move this part of the equation up here, so that we have room to work. To take the derivative of this we need to apply the chain rule. So we start by moving the square to the front and multiply that by the derivative of the stuff inside the parentheses. These parts don't contain a term for the intercept, so they go away. Then we simplify by multiplying two by negative one. And this is the derivative of the first part, so we plug it in. Now we need to take the derivative of the next two parts. I'll leave that as an exercise for the viewer. Bam! Let's move the derivative up here, so that it's not taking up half the screen. Now that we have the derivative, Gradient Descent will use it to find where the sum of squared residuals is lowest. Note: if we were using least squares\"),\n",
       " Document(metadata={}, page_content=\"so that it's not taking up half the screen. Now that we have the derivative, Gradient Descent will use it to find where the sum of squared residuals is lowest. Note: if we were using least squares to solve for the optimal value for the intercept, we would simply find where the slope of the curve equals zero. In contrast gradient descent finds the minimum value by taking steps from an initial guess until it reaches the best value. This makes Gradient Descent very useful when it is not possible to solve for where the derivative equals zero. And this is why Gradient Descent can be used in so many different situations. Bam! Remember, we started by setting the intercept to a random number. In this case that was zero. So we plug zero into the derivative and we get negative 5.7. So, when the intercept equals 0, the slope of the curve equals negative 5.7. Note: the closer we get to the optimal value for the intercept, the closer the slope of the curve gets to zero. This means that when the\"),\n",
       " Document(metadata={}, page_content=\"equals 0, the slope of the curve equals negative 5.7. Note: the closer we get to the optimal value for the intercept, the closer the slope of the curve gets to zero. This means that when the slope of the curve is close to zero, then we should take baby steps, because we are close to the optimal value. And when the slope is far from zero, then we should take big steps because we are far from the optimal value. However, if we take a super, huge step, then we would increase the sum of the squared residuals. So the size of the step should be related to the slope, since it tells us if we should take a baby step or a big step. But we need to make sure the big step is not too big. Gradient Descent determines the step size by multiplying the slope by a small number called the learning rate. Note: we'll talk more about learning rates later. When the intercept equals 0, the step size equals negative 5.7. With the step size, we can calculate a new intercept. The new intercept is the old\"),\n",
       " Document(metadata={}, page_content=\"Note: we'll talk more about learning rates later. When the intercept equals 0, the step size equals negative 5.7. With the step size, we can calculate a new intercept. The new intercept is the old intercept minus the step size. So we plug in the numbers, and the new intercept equals 0.57. Bam! In one big step, we moved much closer to the optimal value for the intercept. Going back to the original data and the original line, with the intercept equals 0, we can see how much the residuals shrink when the intercept equals 0.57. Now let's take another step closer to the optimal value for the intercept. To take another step, we go back to the derivative and plug in the new intercept, and that tells us the slope of the curve equals negative 2.3. Now let's calculate the step size. By plugging in negative 2.3 for the slope, and 0.1 for the learning rate, ultimately the step size is negative 0.23. And the new intercept equals 0.8. Now we can compare the residuals when the intercept equals 0.57\"),\n",
       " Document(metadata={}, page_content=\"negative 2.3 for the slope, and 0.1 for the learning rate, ultimately the step size is negative 0.23. And the new intercept equals 0.8. Now we can compare the residuals when the intercept equals 0.57 to when the intercept equals 0.8. Overall the sum of the squared residuals is getting smaller. Notice that the first step was relatively large, compared to the second step. Now let's calculate the derivative at the new intercept: and we get negative 0.9. The step size equals negative 0.09, and the new intercept equals 0.89. Now we increase the intercept from 0.8 to 0.89, then we take another step and the new intercept equals 0.92. And then we take another step, and the new intercept equals 0.94. And then we take another step, and the new intercept equals 0.95. Notice how each step gets smaller and smaller the closer we get to the bottom of the curve. After six steps, the gradient ascent estimate for the intercept is 0.95. Note: the least squares estimate for the intercept is also 0.95. so\"),\n",
       " Document(metadata={}, page_content='and smaller the closer we get to the bottom of the curve. After six steps, the gradient ascent estimate for the intercept is 0.95. Note: the least squares estimate for the intercept is also 0.95. so we know that gradient descent has done its job, but without comparing its solution to a gold standard, how does gradient descent know to stop taking steps? Gradient Descent stops when the step size is very close to zero. The step size will be very close to zero when the slope is very close to zero. In practice, the minimum step size equals 0.001 or smaller. So if this slope equals 0.009, then we would plug in 0.009 for the slope and 0.1 for the learning rate and get 0.0009, which is smaller than 0.001, so gradient descent would stop. That said, gradient descent also includes a limit on the number of steps it will take before giving up. In practice, the maximum number of steps equals 1000 or greater. So, even if the step size is large, if there have been more than the maximum number of'),\n",
       " Document(metadata={}, page_content=\"number of steps it will take before giving up. In practice, the maximum number of steps equals 1000 or greater. So, even if the step size is large, if there have been more than the maximum number of steps, gradient descent will stop. Okay, let's review what we've learned so far. The first thing we did is decide to use the sum of the squared residuals as the loss function to evaluate how well a line fits the data. Then, we took the derivative of the sum of the squared residuals. In other words, we took the derivative of the loss function. Then, we picked a random value for the intercept, in this case we set the intercept to be equal to zero. Then, we calculated the derivative when the intercept equals zero, plugged that slope into the step size calculation, and then calculated the new intercept, the difference between the old intercept and the step size. Lastly, we plugged the new intercept into the derivative and repeated everything until step size was close to zero. Double bam! Now\"),\n",
       " Document(metadata={}, page_content=\"the difference between the old intercept and the step size. Lastly, we plugged the new intercept into the derivative and repeated everything until step size was close to zero. Double bam! Now that we understand how gradient descent can calculate the intercept, let's talk about how to estimate the intercept and the slope. Just like before, we'll use the sum of the squared residuals as the loss function. This is a 3D graph of the loss function for the different values for the intercept and the slope. This axis is the sum of the squared residuals, this axis represents different values for the slope, and this axis represents different values for the intercept. We want to find the values for the intercept and slope that give us the minimum sum of the squared residuals. So, just like before, we need to take the derivative of this function. And just like before, we'll take the derivative with respect to the intercept. But, unlike before, we'll also take the derivative with respect to the\"),\n",
       " Document(metadata={}, page_content=\"we need to take the derivative of this function. And just like before, we'll take the derivative with respect to the intercept. But, unlike before, we'll also take the derivative with respect to the slope. We'll start by taking the derivative with respect to the intercept. Just like before, we'll take the derivative of each part. And, just like before, we'll use the chain rule and move the square to the front, and multiply that by the derivative of the stuff inside the parentheses. [Music] Since we are taking the derivative with respect to the intercept, we treat the slope like a constant, and the derivative of a constant is zero. So, we end up with negative one, just like before. Then we simplify by multiplying two by negative one. And this is the derivative of the first part. So we plug it in. Likewise, we replace these terms with their derivatives. So this whole thing is the derivative of the sum of squared residuals with respect to the intercept. Now let's take the derivative of\"),\n",
       " Document(metadata={}, page_content=\"it in. Likewise, we replace these terms with their derivatives. So this whole thing is the derivative of the sum of squared residuals with respect to the intercept. Now let's take the derivative of the sum of the squared residuals with respect to the slope. Just like before, we take the derivative of each part and, just like before, we'll use the chain rule to move the square to the front and multiply that by the derivative of the stuff inside the parentheses. Since we are taking the derivative with respect to the slope, we treat the intercept like a constant and the derivative of a constant is zero. So we end up with negative 0.5. Then we simplify by moving the negative 0.5 to the front. Note: I left the 0.5 in bold instead of multiplying it by 2 to remind us that 0.5 is the weight for the first sample. And this is the derivative of the first part. So we plug it in. Likewise, we replace these terms with their derivatives. Again, 2.3 and 2.9 are in bold to remind us that they are the\"),\n",
       " Document(metadata={}, page_content=\"first sample. And this is the derivative of the first part. So we plug it in. Likewise, we replace these terms with their derivatives. Again, 2.3 and 2.9 are in bold to remind us that they are the weights of the second and third samples. Here's the derivative of the sum of the squared residuals with respect to the intercept, and here's the derivative with respect to the slope. Note: when you have two or more derivatives of the same function they are called a gradient. We will use this gradient to descend to the lowest point in the loss function, which, in this case, is the sum of the squared residuals. Thus, this is why the algorithm is called Gradient Descent. Bam! Just like before, we'll start by picking a random number for the intercept. In this case, we'll set the intercept to be equal to zero, and we'll pick a random number for the slope. In this case we'll set the slope to be 1. Thus, this line, with intercept equals 0 and slope equals 1, is where we will start. Now, let's plug\"),\n",
       " Document(metadata={}, page_content=\"to zero, and we'll pick a random number for the slope. In this case we'll set the slope to be 1. Thus, this line, with intercept equals 0 and slope equals 1, is where we will start. Now, let's plug in 0 for the intercept and 1 for the slope. And that gives us two slopes. Now, we plug the slopes into the step size formulas, and multiply by the learning rate, which this time we set to 0.01. Note: The larger learning rate that we used in the first example doesn't work this time. Even after a bunch of steps, Gradient Descent doesn't arrive at the correct answer. This means that Gradient Descent can be very sensitive to the learning rate. The good news is that, in practice, a reasonable learning rate can be determined automatically by starting large and getting smaller with each step. So, in theory, you shouldn't have to worry too much about the learning rate. Anyway, we do the math and get two step sizes. Now we calculate the new intercept and new slope by plugging in the old intercept\"),\n",
       " Document(metadata={}, page_content=\"theory, you shouldn't have to worry too much about the learning rate. Anyway, we do the math and get two step sizes. Now we calculate the new intercept and new slope by plugging in the old intercept and the old slope, and the step sizes. And we end up with a new intercept and a new slope. This is the line we started with and this is the new line after the first step. Now we just repeat what we did until all of the step sizes are very small, or we reach the maximum number of steps. This is the best fitting line, with intercept equals 0.95 and slope equals 0.64,  the same values we get from least squares. Double bam! We now know how Gradient Descent optimizes two parameters, the slope and the intercept. If we had more parameters then we just take more derivatives and everything else stays the same. Triple bam! Note: the sum of the squared residuals is just one type of Loss Function. However, there are tons of other loss functions that work with other types of data. Regardless of which\"),\n",
       " Document(metadata={}, page_content=\"the same. Triple bam! Note: the sum of the squared residuals is just one type of Loss Function. However, there are tons of other loss functions that work with other types of data. Regardless of which Loss Function you use, Gradient Descent works the same way. Step 1: take the derivative of the loss function for each parameter in it. In fancy machine learning lingo, take the gradient of the loss function. Step 2: pick random values for the parameters. Step 3: plug the parameter values into the derivatives (ahem, the gradient). Step 4: calculate the step sizes. Step 5: calculate the new parameters. Now go back to step 3 and repeat\\xa0until step size is very small or you reach the maximum number of steps. One last thing before we're done. In our example we only had three data points, so the math didn't take very long. But when you have millions of data points it can take a long time. So there is a thing called Stochastic Gradient Descent that uses a randomly selected subset of the data at\"),\n",
       " Document(metadata={}, page_content=\"didn't take very long. But when you have millions of data points it can take a long time. So there is a thing called Stochastic Gradient Descent that uses a randomly selected subset of the data at every step rather than the full data set. This reduces the time spent calculating the derivatives of the loss function. That's all. Stochastic Gradient Descent sounds fancy, but it's no big deal. Hooray! We've made it to the end of another exciting StatQuest. If you like this StatQuest and want to see more, please subscribe. And if you want to support StatQuest, well, consider buying one or two of my original songs, or buying a StatQuest t-shirt or hoodie. The links\\xa0are in the description below. Alright, until next time. Quest on!\")]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3ad3a17",
   "metadata": {},
   "source": [
    "# Step 3: Indexing (Embedding Generation and storing in Vector store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "a9c1105c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_classic.vectorstores import FAISS\n",
    "embedding = GoogleGenerativeAIEmbeddings(model='gemini-embedding-001')\n",
    "vector_store = FAISS.from_documents(chunks, embedding=embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "5c16b046",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: '1432fbb2-2abf-402c-b9cb-e251397ae694',\n",
       " 1: 'e81f3140-c38e-4494-9a85-037e685988de',\n",
       " 2: '6690a87f-2c1e-43e8-b8f9-bf940e08b0d4',\n",
       " 3: '78e0ad6c-64bb-459c-89cf-83415905a918',\n",
       " 4: '6615cffd-797b-4f2f-bc41-53740afcdeb2',\n",
       " 5: 'bc5ff951-efdf-4870-a4eb-60559d3b43a5',\n",
       " 6: '7658c2a7-6262-442f-b838-4674ae0af4a1',\n",
       " 7: '78b0b5ba-7e1e-41ba-8fcb-7b68e90ddc7a',\n",
       " 8: '20ee93b5-b166-49b6-9ee8-51d6365b75ae',\n",
       " 9: '8b01033d-f092-46f0-8282-c13b8db76ca6',\n",
       " 10: '25bd94d0-16ce-4b27-b028-45eb753d1c57',\n",
       " 11: '613881b6-9e7f-4fe3-821f-442598322310',\n",
       " 12: '3df8cc61-6e71-4ec0-8064-a07217e8008a',\n",
       " 13: '855540c4-bf8b-44c3-b572-993a9e7f6e52',\n",
       " 14: '43c3fa27-39ca-418a-94c1-75ec3e8d0d60',\n",
       " 15: 'ceabe6d6-8c08-4f1e-8e80-e9d3409a5a7b',\n",
       " 16: '6bd335ae-0a84-41db-b841-30099ea4a4ab',\n",
       " 17: 'b1c70390-6b66-4e34-9c4e-4a4c1bd01c9a',\n",
       " 18: '326df5e9-2be6-40fc-81c3-d42ce3823015',\n",
       " 19: '7fdf063a-f68f-49cf-9736-1b30474c8950',\n",
       " 20: '854fd5ef-32b0-40a3-a25f-9acbc99fa01f',\n",
       " 21: 'b153262a-e246-4f32-b306-710499470fb3'}"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_store.index_to_docstore_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "85bd52d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_store.get_by_ids(['79ca8801-2ba4-4234-a6fe-5aef87cd52ca'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "535d8678",
   "metadata": {},
   "source": [
    "# Step 4: Retriever "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "5488d044",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vector_store.as_retriever(search_type='similarity', search_kwargs={'k':4})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "b5ceca5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='1432fbb2-2abf-402c-b9cb-e251397ae694', metadata={}, page_content=\"Gradient Descent is decent at estimating parameters. StatQuest! Hello! I'm Josh Starmer and welcome to StatQuest. Today we're going to learn about Gradient Descent and we're going to go through the algorithm step by step. Note: this StatQuest assumes you already understand the basics of least squares and linear regression, so if you're not already down with that, check out the Quest. In statistics, machine learning, and other data science fields, we optimize a lot of stuff. When we fit a line with linear regression, we optimize the intercept and the slope. When we use logistic regression, we optimize a squiggle. And when we use t-SNE, we optimize clusters. These are just a few examples of the stuff we optimize, there are tons more. The cool thing is that Gradient Descent can optimize all these things, and much more. So, if we learn how to optimize this line using Gradient Descent, then we'll have learned the strategy that optimizes this squiggle, and these clusters, and many more of\"),\n",
       " Document(id='7fdf063a-f68f-49cf-9736-1b30474c8950', metadata={}, page_content=\"theory, you shouldn't have to worry too much about the learning rate. Anyway, we do the math and get two step sizes. Now we calculate the new intercept and new slope by plugging in the old intercept and the old slope, and the step sizes. And we end up with a new intercept and a new slope. This is the line we started with and this is the new line after the first step. Now we just repeat what we did until all of the step sizes are very small, or we reach the maximum number of steps. This is the best fitting line, with intercept equals 0.95 and slope equals 0.64,  the same values we get from least squares. Double bam! We now know how Gradient Descent optimizes two parameters, the slope and the intercept. If we had more parameters then we just take more derivatives and everything else stays the same. Triple bam! Note: the sum of the squared residuals is just one type of Loss Function. However, there are tons of other loss functions that work with other types of data. Regardless of which\"),\n",
       " Document(id='e81f3140-c38e-4494-9a85-037e685988de', metadata={}, page_content=\"these things, and much more. So, if we learn how to optimize this line using Gradient Descent, then we'll have learned the strategy that optimizes this squiggle, and these clusters, and many more of the optimization problems we have in statistics, machine learning, and data science. So let's start with a simple data set. On the x-axis we have weight. On the y-axis we have height. If we fit a line to the data and someone tells us that they weigh 1.5, we can use the line to predict that they will be 1.9 tall. So let's learn how Gradient Descent can fit a line to data by finding the optimal values for the intercept and the slope. Actually, we'll start by using Gradient Descent to find the intercept. Then, once we understand how Gradient Descent works, we'll use it to solve for the intercept and the slope. So, for now, let's just plug in the Least Squares estimate for the slope, 0.64, and we'll use Gradient Descent to find the optimal value for the intercept. The first thing we do is pick\"),\n",
       " Document(id='b1c70390-6b66-4e34-9c4e-4a4c1bd01c9a', metadata={}, page_content=\"first sample. And this is the derivative of the first part. So we plug it in. Likewise, we replace these terms with their derivatives. Again, 2.3 and 2.9 are in bold to remind us that they are the weights of the second and third samples. Here's the derivative of the sum of the squared residuals with respect to the intercept, and here's the derivative with respect to the slope. Note: when you have two or more derivatives of the same function they are called a gradient. We will use this gradient to descend to the lowest point in the loss function, which, in this case, is the sum of the squared residuals. Thus, this is why the algorithm is called Gradient Descent. Bam! Just like before, we'll start by picking a random number for the intercept. In this case, we'll set the intercept to be equal to zero, and we'll pick a random number for the slope. In this case we'll set the slope to be 1. Thus, this line, with intercept equals 0 and slope equals 1, is where we will start. Now, let's plug\")]"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever.invoke('is the topic of Gradient Descent is discussed in this video')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25462b50",
   "metadata": {},
   "source": [
    "# Step 5: Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "ca59087e",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = GoogleGenerativeAI(model='gemini-2.5-flash', temperature=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "3a09e9da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "prompt = PromptTemplate(\n",
    "    template=\n",
    "    \"\"\"\n",
    "You are a helpful assistant. Use only the provided transcript context.\n",
    "\n",
    "If the answer can be determined logically from the context, answer it.\n",
    "If the context shows the topic was NOT discussed, answer \"No\".\n",
    "If the context is truly insufficient to tell, say \"I don't know.\"\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\"\"\",\n",
    "input_variables=['context', 'question']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "2f83a834",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = 'Gradient Descent algorithm explanation'\n",
    "retrieved_docs = retriever.invoke(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "79ae40f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first sample. And this is the derivative of the first part. So we plug it in. Likewise, we replace these terms with their derivatives. Again, 2.3 and 2.9 are in bold to remind us that they are the weights of the second and third samples. Here's the derivative of the sum of the squared residuals with respect to the intercept, and here's the derivative with respect to the slope. Note: when you have two or more derivatives of the same function they are called a gradient. We will use this gradient to descend to the lowest point in the loss function, which, in this case, is the sum of the squared residuals. Thus, this is why the algorithm is called Gradient Descent. Bam! Just like before, we'll start by picking a random number for the intercept. In this case, we'll set the intercept to be equal to zero, and we'll pick a random number for the slope. In this case we'll set the slope to be 1. Thus, this line, with intercept equals 0 and slope equals 1, is where we will start. Now, let's plug\n",
      "Gradient Descent is decent at estimating parameters. StatQuest! Hello! I'm Josh Starmer and welcome to StatQuest. Today we're going to learn about Gradient Descent and we're going to go through the algorithm step by step. Note: this StatQuest assumes you already understand the basics of least squares and linear regression, so if you're not already down with that, check out the Quest. In statistics, machine learning, and other data science fields, we optimize a lot of stuff. When we fit a line with linear regression, we optimize the intercept and the slope. When we use logistic regression, we optimize a squiggle. And when we use t-SNE, we optimize clusters. These are just a few examples of the stuff we optimize, there are tons more. The cool thing is that Gradient Descent can optimize all these things, and much more. So, if we learn how to optimize this line using Gradient Descent, then we'll have learned the strategy that optimizes this squiggle, and these clusters, and many more of\n",
      "the same. Triple bam! Note: the sum of the squared residuals is just one type of Loss Function. However, there are tons of other loss functions that work with other types of data. Regardless of which Loss Function you use, Gradient Descent works the same way. Step 1: take the derivative of the loss function for each parameter in it. In fancy machine learning lingo, take the gradient of the loss function. Step 2: pick random values for the parameters. Step 3: plug the parameter values into the derivatives (ahem, the gradient). Step 4: calculate the step sizes. Step 5: calculate the new parameters. Now go back to step 3 and repeat until step size is very small or you reach the maximum number of steps. One last thing before we're done. In our example we only had three data points, so the math didn't take very long. But when you have millions of data points it can take a long time. So there is a thing called Stochastic Gradient Descent that uses a randomly selected subset of the data at\n",
      "theory, you shouldn't have to worry too much about the learning rate. Anyway, we do the math and get two step sizes. Now we calculate the new intercept and new slope by plugging in the old intercept and the old slope, and the step sizes. And we end up with a new intercept and a new slope. This is the line we started with and this is the new line after the first step. Now we just repeat what we did until all of the step sizes are very small, or we reach the maximum number of steps. This is the best fitting line, with intercept equals 0.95 and slope equals 0.64,  the same values we get from least squares. Double bam! We now know how Gradient Descent optimizes two parameters, the slope and the intercept. If we had more parameters then we just take more derivatives and everything else stays the same. Triple bam! Note: the sum of the squared residuals is just one type of Loss Function. However, there are tons of other loss functions that work with other types of data. Regardless of which\n"
     ]
    }
   ],
   "source": [
    "context_text = '\\n'.join(doc.page_content for doc in retrieved_docs)\n",
    "print(context_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "db1be9ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_prompt = prompt.invoke({'context':context_text, 'question':question})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f917c306",
   "metadata": {},
   "source": [
    "# Step 6 Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "0594ee5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Gradient Descent algorithm is explained step by step:\n",
      "\n",
      "1.  **Step 1:** Take the derivative of the loss function for each parameter in it (also called taking the gradient of the loss function).\n",
      "2.  **Step 2:** Pick random values for the parameters. For example, the intercept might be set to zero and the slope to one.\n",
      "3.  **Step 3:** Plug the parameter values into the derivatives (the gradient).\n",
      "4.  **Step 4:** Calculate the step sizes.\n",
      "5.  **Step 5:** Calculate the new parameters.\n",
      "    Then, go back to step 3 and repeat until the step size is very small or the maximum number of steps is reached.\n",
      "\n",
      "The algorithm uses the gradient to descend to the lowest point in the loss function, which is why it's called Gradient Descent. It can optimize various things like the intercept and slope in linear regression, a squiggle in logistic regression, or clusters in t-SNE.\n"
     ]
    }
   ],
   "source": [
    "answer = llm.invoke(final_prompt)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eadd210e",
   "metadata": {},
   "source": [
    "# Building a Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "3f4f7ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnableParallel, RunnablePassthrough, RunnableLambda\n",
    "from langchain_core.output_parsers import StrOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "027219a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_docs(retrieved_docs):\n",
    "    context_text = '\\n\\n'.join(doc.page_content for doc in retrieved_docs)\n",
    "    return context_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "f1b29d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "parallel_chain = RunnableParallel({\n",
    "    'context':retriever | RunnableLambda(format_docs),\n",
    "    'question' : RunnablePassthrough()\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "21e513d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'context': \"Gradient Descent is decent at estimating parameters. StatQuest! Hello! I'm Josh Starmer and welcome to StatQuest. Today we're going to learn about Gradient Descent and we're going to go through the algorithm step by step. Note: this StatQuest assumes you already understand the basics of least squares and linear regression, so if you're not already down with that, check out the Quest. In statistics, machine learning, and other data science fields, we optimize a lot of stuff. When we fit a line with linear regression, we optimize the intercept and the slope. When we use logistic regression, we optimize a squiggle. And when we use t-SNE, we optimize clusters. These are just a few examples of the stuff we optimize, there are tons more. The cool thing is that Gradient Descent can optimize all these things, and much more. So, if we learn how to optimize this line using Gradient Descent, then we'll have learned the strategy that optimizes this squiggle, and these clusters, and many more of\\n\\nfirst sample. And this is the derivative of the first part. So we plug it in. Likewise, we replace these terms with their derivatives. Again, 2.3 and 2.9 are in bold to remind us that they are the weights of the second and third samples. Here's the derivative of the sum of the squared residuals with respect to the intercept, and here's the derivative with respect to the slope. Note: when you have two or more derivatives of the same function they are called a gradient. We will use this gradient to descend to the lowest point in the loss function, which, in this case, is the sum of the squared residuals. Thus, this is why the algorithm is called Gradient Descent. Bam! Just like before, we'll start by picking a random number for the intercept. In this case, we'll set the intercept to be equal to zero, and we'll pick a random number for the slope. In this case we'll set the slope to be 1. Thus, this line, with intercept equals 0 and slope equals 1, is where we will start. Now, let's plug\\n\\nnumber of steps it will take before giving up. In practice, the maximum number of steps equals 1000 or greater. So, even if the step size is large, if there have been more than the maximum number of steps, gradient descent will stop. Okay, let's review what we've learned so far. The first thing we did is decide to use the sum of the squared residuals as the loss function to evaluate how well a line fits the data. Then, we took the derivative of the sum of the squared residuals. In other words, we took the derivative of the loss function. Then, we picked a random value for the intercept, in this case we set the intercept to be equal to zero. Then, we calculated the derivative when the intercept equals zero, plugged that slope into the step size calculation, and then calculated the new intercept, the difference between the old intercept and the step size. Lastly, we plugged the new intercept into the derivative and repeated everything until step size was close to zero. Double bam! Now\\n\\nthe graph. And if the intercept equals 0.5, then we would get this point. And for increasing values for the intercept we get these points. Of the points that we calculated for the graph, this one has the lowest sum of squared residuals. But is it the best we can do? What if the best value for the intercept is somewhere between these values? A slow and painful method for finding the minimal sum of the squared residuals is to plug and chug a bunch more values for the intercept. Don't despair! Gradient Descent is way more efficient. Gradient Descent only does a few calculations far from the optimal solution, and increases the number of calculations closer to the optimal value. In other words, gradient descent identifies the optimal value by taking big steps when it is far away, and baby steps when it is close. So let's get back to using gradient ascent to find the optimal value for the intercept, starting from a random value. In this case, the random value was zero. When we calculated\",\n",
       " 'question': 'What is the algorithm discussed'}"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parallel_chain.invoke('What is the algorithm discussed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "0059c8f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "e351d5ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_chain = parallel_chain | prompt | llm | parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "6c41dcbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This StatQuest video introduces Gradient Descent, an algorithm used to optimize parameters in statistics, machine learning, and data science. It assumes prior knowledge of least squares and linear regression. Gradient Descent can optimize various elements, such as the intercept and slope in linear regression, squiggles in logistic regression, and clusters in t-SNE.\n",
      "\n",
      "The algorithm's steps involve:\n",
      "1.  Deciding on a loss function, such as the sum of the squared residuals, to evaluate how well a line fits the data.\n",
      "2.  Taking the derivative of this loss function.\n",
      "3.  Picking random initial values for parameters (e.g., intercept and slope).\n",
      "4.  Calculating the derivative at the current parameter values.\n",
      "5.  Plugging that derivative into a step size calculation.\n",
      "6.  Calculating new parameter values by subtracting the step size from the old values.\n",
      "7.  Repeating these steps until the step size is close to zero or a maximum number of steps (typically 1000 or more) is reached.\n",
      "\n",
      "The term \"gradient\" refers to two or more derivatives of the same function, and the algorithm is named Gradient Descent because it uses this gradient to descend to the lowest point in the loss function.\n",
      "\n",
      "For large datasets, a variation called Stochastic Gradient Descent is introduced. It uses a randomly selected subset of the data at every step instead of the full dataset, which reduces the time spent calculating the derivatives of the loss function.\n"
     ]
    }
   ],
   "source": [
    "print(main_chain.invoke('Can you summarize the video'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba7e93ba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
